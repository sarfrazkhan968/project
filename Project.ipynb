{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e52f1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import pathlib\n",
    "from glob import glob\n",
    "import os\n",
    "import PIL\n",
    "import imageio\n",
    "from scipy.signal import convolve2d\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn import metrics\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d901fbc1",
   "metadata": {},
   "source": [
    "# Reading Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c917f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "train_path='/content/drive/MyDrive/APOD_Train/'\n",
    "valid_path='/content/drive/MyDrive/APOD_Valid/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2428e1",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trpth=os.listdir(train_path)\n",
    "valpth=os.listdir(valid_path)\n",
    "trn_img=[]\n",
    "val_img=[]\n",
    "cats_img=['Fake','Real']\n",
    "for i in trpth:\n",
    "    trn_img.append(len(os.listdir(os.path.join(train_path,i))))\n",
    "for i in valpth:\n",
    "    val_img.append(len(os.listdir(os.path.join(valid_path,i))))\n",
    "tot=[sum(trn_img),sum(val_img)]\n",
    "trn_img.append(tot[0])\n",
    "val_img.append(tot[1])\n",
    "cats_img.append(\"Total\")\n",
    "piedata=pandas.DataFrame({\"Category\":cats_img,\"Train\":trn_img,\"Valid\":val_img})\n",
    "piedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d747216",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=px.pie(piedata,names=\"Category\",values=\"Train\",color=\"Category\",title=\"Number of Images Train Set\",height=400,width=400,\n",
    "           color_discrete_sequence=px.colors.qualitative.Vivid)\n",
    "fig.update_traces(textposition='inside',textinfo='percent+label+value')\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        family=\"Times New Roman, Bold\",\n",
    "        size=20,\n",
    "        color=\"black\"\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d923a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = pathlib.Path(train_path)\n",
    "\n",
    "trn_real = list(train_dir.glob(\"Real/*\"))\n",
    "trn_fake = list(train_dir.glob(\"Fake/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9a8ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = PIL.Image.open(trn_real[30])\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.title(\"Real Astronimical Object\",fontsize=15,color=\"#357EC7\")\n",
    "plt.imshow(img1)\n",
    "\n",
    "img2 = PIL.Image.open(trn_fake[30])\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.title(\"Fake Astronimical Object\",fontsize=15,color=\"#357EC7\")\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ccf81b",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46a69d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image.ImageDataGenerator(rescale=1. / 255,\n",
    "                                   rotation_range=50,\n",
    "                                   width_shift_range=0.15,\n",
    "                                   height_shift_range=0.15,\n",
    "                                   shear_range=0.3,\n",
    "                                   zoom_range=0.3,\n",
    "                                   vertical_flip=True)\n",
    "\n",
    "val_datagen = image.ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "bsiz = 32\n",
    "img_h,img_w = 128,128\n",
    "labels=os.listdir(train_path)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b06f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug_train = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes=labels,\n",
    "        target_size=(img_h, img_w),\n",
    "        batch_size=bsiz,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d719a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug_val = val_datagen.flow_from_directory(\n",
    "        valid_path,\n",
    "        classes=labels,\n",
    "        target_size=(img_h,img_w),\n",
    "        batch_size=bsiz,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b9795",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d568883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_Pretrained(dptlm,mdlnm):\n",
    "    mdl_trl = dptlm\n",
    "    inpinslyr = keras.layers.Input(shape=(img_h,img_w, 3))\n",
    "    hddninslyr = keras.layers.Conv2D(3, (3, 3), padding='same')(inpinslyr)\n",
    "    hddninslyr = mdl_trl(hddninslyr)\n",
    "    hddninslyr = keras.layers.GlobalAveragePooling2D()(hddninslyr)\n",
    "    hddninslyr = keras.layers.BatchNormalization()(hddninslyr)\n",
    "    hddninslyr = keras.layers.Dropout(0.5)(hddninslyr)\n",
    "    hddninslyr = keras.layers.Dense(256, activation='relu')(hddninslyr)\n",
    "    hddninslyr = keras.layers.BatchNormalization()(hddninslyr)\n",
    "    hddninslyr = keras.layers.Dropout(0.5)(hddninslyr)\n",
    "    outinslyr = keras.layers.Dense(2,activation = 'softmax')(hddninslyr)\n",
    "    deepemo = keras.models.Model(inpinslyr,outinslyr, name=\"{}\".format(mdlnm))\n",
    "    deepemo.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    deepemo.summary()\n",
    "    return deepemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87bada7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
